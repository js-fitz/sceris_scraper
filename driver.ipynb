{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "addtl_params = [ # params to include in search results (but not set specifically as search params)\n",
    "    'Archive Date', 'Permit Number', 'Status', # this is so the metadatadf will contain these details\n",
    "    'Unit', 'Primary Street Number', 'Street Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 unique wards identified\n"
     ]
    }
   ],
   "source": [
    "# identify list of all wards\n",
    "wards = get_wards()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each ward in list of all wards, get these search results:\n",
    "- doc_type = C/O (certificate of occupancy)\n",
    "- ward_name = (ward for this iteration)\n",
    "- date >= jan 1 2000\n",
    "\n",
    "- Then, try to download all the files for this ward. \n",
    "- Simultaneously compile a \"metadata df\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————————————————————————\n",
      "> Filtering results...setting parameters...done.\n",
      " > Iterating over 1175 files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005b8f0e8135415cabafc20916f1fdda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1175.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Prompting download (file 1/1175)...\n",
      "  > Clicking initial download button…\n",
      "  > Clicking first \"Save\" button…\n",
      "    > '251 MERIDIAN [coo1072086] 08_11_2020.tif' downloaded to ward_name/01 east boston\n",
      "  > Prompting download (file 2/1175)...\n",
      "  > Clicking initial download button…\n",
      "  > Clicking first \"Save\" button…\n",
      "    > '149 LEXINGTON [coo1035015] 03_06_2020.tif' downloaded to ward_name/01 east boston\n",
      "  > Prompting download (file 3/1175)...\n",
      "  > Clicking initial download button…\n",
      "  > Clicking first \"Save\" button…\n",
      "    > '209 HAVRE [coo1029795] 03_06_2020.tif' downloaded to ward_name/01 east boston\n",
      "  > Prompting download (file 4/1175)...\n",
      "  > Clicking initial download button…\n",
      "  > Clicking first \"Save\" button…\n",
      "    > '16 BOARDMAN [coo921861temp] 03_02_2020.tif' downloaded to ward_name/01 east boston\n",
      "  > Prompting download (file 5/1175)...\n",
      "  > Clicking initial download button…\n",
      "  > Clicking first \"Save\" button…\n",
      "    > '336 CHELSEA [COO959376] 06_12_2019.tif' downloaded to ward_name/01 east boston\n",
      "  > Prompting download (file 6/1175)...\n",
      "  > Clicking initial download button…\n",
      "  > Clicking first \"Save\" button…\n",
      "    > '108 WEBSTER [COO949929] 06_12_2019.tif' downloaded to ward_name/01 east boston\n",
      "  > Prompting download (file 7/1175)...\n",
      "  > Clicking initial download button…\n",
      "  > Clicking first \"Save\" button…\n",
      "    > '77 MORRIS [COO943274] 06_12_2019.tif' downloaded to ward_name/01 east boston\n",
      "  > Prompting download (file 8/1175)...\n",
      "  [FATAL ERROR] - scraper failed on item 77 MORRIS [COO943274] 06_12_2019.tif\n",
      "\n",
      "         waiting 1 seconds...   "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'max_attempts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/sceris_scraper/scraper.py\u001b[0m in \u001b[0;36mscraper_get\u001b[0;34m(search_param_input, addtl_params, max_down_wait_sec, max_attempts, start_at)\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ui-grid-row-focused'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dsplay/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_class_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \"\"\"\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dsplay/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[name=\"%s\"]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dsplay/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dsplay/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".ui-grid-row-focused\"}\n  (Session info: chrome=86.0.4240.198)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f5e7d9fd0fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             scraper_get(search_param_input, addtl_params,\n\u001b[0m\u001b[1;32m     27\u001b[0m                         start_at=config.restart_on_idx) # pickup where last attempt left off\n",
      "\u001b[0;32m~/Desktop/sceris_scraper/scraper.py\u001b[0m in \u001b[0;36mscraper_get\u001b[0;34m(search_param_input, addtl_params, max_down_wait_sec, max_attempts, start_at)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'  [FATAL ERROR] - scraper failed on item {config.target_fname}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f5e7d9fd0fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n\\n  [ RE-LAUNCHING DRIVER ... ({attempt+1}/{max_attempts})]\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'max_attempts' is not defined"
     ]
    }
   ],
   "source": [
    "ward_done = True # use if starting a new ward, fresh\n",
    "# ward_done = False # use if manually re-starting mid-ward\n",
    "\n",
    "wards = sorted(list(set([w.lower() for w in wards])))\n",
    "for w in wards:\n",
    "    \n",
    "    try:\n",
    "        config.restart_on_idx # is there a restart location identified?\n",
    "        if ward_done: # is the ward done?\n",
    "            config.restart_on_idx = 0\n",
    "            config.metadata_df = pd.DataFrame()\n",
    "    except:\n",
    "        config.restart_on_idx = 0 # fresh notebook\n",
    "        config.metadata_df = pd.DataFrame()\n",
    "    \n",
    "    # set input params\n",
    "    search_param_input = {\n",
    "        'Ward Name': w,\n",
    "        'Document Type': 'C/O', } # by default, SINCE_2000 is also activated\n",
    "      \n",
    "    attempt = 0\n",
    "    max_fails = 999 # basically don't stop trying unless a human cancels the operation\n",
    "    for attempt in range(max_fails):\n",
    "        \n",
    "        try:\n",
    "            scraper_get(search_param_input, addtl_params,\n",
    "                        start_at=config.restart_on_idx) # pickup where last attempt left off\n",
    "            \n",
    "        except:\n",
    "\n",
    "            # scrape re-try (wait 15 seconds between)\n",
    "            try: d.quit()\n",
    "            except: pass\n",
    "            wait_amt = 15\n",
    "            for t_wait in range(wait_amt):\n",
    "                print(f'\\r         waiting {wait_amt-t_wait} seconds...  ', end='')\n",
    "                time.sleep(1)\n",
    "\n",
    "            print(f'\\n\\n  [ RE-LAUNCHING DRIVER ... ({attempt+1}/{max_fails})]\\n')            \n",
    "            \n",
    "            \n",
    "            # autosave metadata if failure\n",
    "            if 'Ward Name' in config.metadata_df.columns:\n",
    "                config.metadata_df.drop(columns=['Document Type', 'Ward Name'], inplace=True)\n",
    "            config.metadata_df.to_excel(\n",
    "                f'{config.target_dir}/AUTOSAVE_{attempt}_metadata.xls', index=False)\n",
    "                  \n",
    "    \n",
    "    # save metadata when done\n",
    "    if 'Ward Name' in config.metadata_df.columns:\n",
    "            config.metadata_df.drop(columns=['Document Type', 'Ward Name'], inplace=True)\n",
    "    config.metadata_df.to_excel(\n",
    "        f'{config.target_dir}/metadata.xls', index=False)\n",
    "    \n",
    "    # indicate to top of loop to reset \n",
    "    ward_done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
